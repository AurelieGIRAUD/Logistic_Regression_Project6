{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 6 - Create a counterfeit banknote detection algorithm based on Logistic Regression\n",
    "# Part 3 -  Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have selected our 3 principal components, we can now move on to the next and final part, which consists of creating a predictive model to detect the fake banknotes. The problem we want to solve is a binary classification and the dataset is labelled so this is a supervised problem. \n",
    "The size of the dataset is relatively small and the main focus is to be accurate (Remember: we want to detect fake banknotes).\n",
    "Therefore, Logistic Regression is especially indicated for this case-study. \n",
    "\n",
    "This part include all the following steps:\n",
    "\n",
    "    âœ… Create a predictive model based on Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import boxplot_stats  \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "X_PCA1 = pd.read_csv(Path.cwd()/'dataset_PCA.csv',index_col=0)\n",
    "X_PCA2 = pd.read_csv(Path.cwd()/'dataset_cleaned_PCA.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step of this project: creating a predictive model based on Logistic Regression to classify the banknotes and detect the fake ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.143117</td>\n",
       "      <td>2.982124</td>\n",
       "      <td>-1.947397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.051636</td>\n",
       "      <td>0.411908</td>\n",
       "      <td>0.249463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.953085</td>\n",
       "      <td>0.808068</td>\n",
       "      <td>0.247236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.035150</td>\n",
       "      <td>-0.359593</td>\n",
       "      <td>-0.537573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.432789</td>\n",
       "      <td>2.792122</td>\n",
       "      <td>1.962433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3\n",
       "0  2.143117  2.982124 -1.947397\n",
       "1 -2.051636  0.411908  0.249463\n",
       "2 -1.953085  0.808068  0.247236\n",
       "3 -2.035150 -0.359593 -0.537573\n",
       "4 -2.432789  2.792122  1.962433"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split between features and labels\n",
    "# With outliers\n",
    "features1 = X_PCA1.iloc[:,1:4] #keeping only the 3 first PCs\n",
    "labels1 =  X_PCA1['is_genuine']\n",
    "\n",
    "features1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.098539</td>\n",
       "      <td>-0.486727</td>\n",
       "      <td>0.228540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.991465</td>\n",
       "      <td>-0.876880</td>\n",
       "      <td>0.154188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.055383</td>\n",
       "      <td>0.404777</td>\n",
       "      <td>-0.479884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.071453</td>\n",
       "      <td>-1.914158</td>\n",
       "      <td>-1.656851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.230656</td>\n",
       "      <td>-0.256015</td>\n",
       "      <td>0.323828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3\n",
       "0 -2.098539 -0.486727  0.228540\n",
       "1 -1.991465 -0.876880  0.154188\n",
       "2 -2.055383  0.404777 -0.479884\n",
       "3  1.071453 -1.914158 -1.656851\n",
       "4 -2.230656 -0.256015  0.323828"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without outliers\n",
    "features2 = X_PCA2.iloc[:,1:4]\n",
    "labels2 =  X_PCA2['is_genuine']\n",
    "\n",
    "features2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between train and test set\n",
    "    # We apply a ratio 80:20\n",
    "    # We stratify based on column is_genuine to keep the proportion of fake and genuine banknotes in both sets\n",
    "    \n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(features1,labels1,stratify= labels1,test_size=0.2) \n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(features2,labels2,stratify= labels2,test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 3) (34, 3) (136,) (34,)\n",
      "(131, 3) (33, 3) (131,) (33,)\n"
     ]
    }
   ],
   "source": [
    "# Quick check on the structure\n",
    "print(X1_train.shape, X1_test.shape, y1_train.shape, y1_test.shape)\n",
    "print(X2_train.shape, X2_test.shape, y2_train.shape, y2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = LogisticRegression(random_state=42)\n",
    "lgr1 = model.fit(X1_train, y1_train)\n",
    "lgr2 = model.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y1_pred = lgr1.predict(X1_test)\n",
    "y2_pred = lgr2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>proba_Fake</th>\n",
       "      <th>proba_Genuine</th>\n",
       "      <th>predict_is_genuine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.310311</td>\n",
       "      <td>1.560640</td>\n",
       "      <td>-0.461629</td>\n",
       "      <td>0.562571</td>\n",
       "      <td>0.437429</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.538766</td>\n",
       "      <td>-1.190436</td>\n",
       "      <td>-0.229546</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.999753</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-1.807811</td>\n",
       "      <td>0.369765</td>\n",
       "      <td>0.050761</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>0.993568</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.198144</td>\n",
       "      <td>-0.378908</td>\n",
       "      <td>-0.257410</td>\n",
       "      <td>0.853560</td>\n",
       "      <td>0.146440</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2.333952</td>\n",
       "      <td>-1.210722</td>\n",
       "      <td>-0.535306</td>\n",
       "      <td>0.976824</td>\n",
       "      <td>0.023176</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PC1       PC2       PC3  proba_Fake  proba_Genuine  \\\n",
       "51   0.310311  1.560640 -0.461629    0.562571       0.437429   \n",
       "7   -2.538766 -1.190436 -0.229546    0.000247       0.999753   \n",
       "68  -1.807811  0.369765  0.050761    0.006432       0.993568   \n",
       "128  1.198144 -0.378908 -0.257410    0.853560       0.146440   \n",
       "120  2.333952 -1.210722 -0.535306    0.976824       0.023176   \n",
       "\n",
       "     predict_is_genuine  \n",
       "51                False  \n",
       "7                  True  \n",
       "68                 True  \n",
       "128               False  \n",
       "120               False  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect the predictions and probabilities associated into a dataframe\n",
    "    # Example for dataset with outliers\n",
    "results = X1_test.copy()\n",
    "results['proba_Fake'] = lgr1.predict_proba(X1_test)[:,0]\n",
    "results['proba_Genuine'] = lgr1.predict_proba(X1_test)[:,1]\n",
    "results['predict_is_genuine'] = lgr1.predict(X1_test)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are many ways of measuring model performance (precision, recall, F1 Score, ROC Curve, etc), we are going to keep this simple and use the accuracy and the confusion matrix (comparable to what we did before with Kmean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9411764705882353 0.9696969696969697\n"
     ]
    }
   ],
   "source": [
    "# Use score method to get accuracy of model\n",
    "score1 = lgr1.score(X1_test, y1_test)\n",
    "score2 = lgr2.score(X2_test, y2_test)\n",
    "print(score1, score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy is 94% on the dataset with outliers and about 97% when we clean the data. Removing the outliers had a positive impact on the accuracy of the model. \n",
    "- The performance of the Logistic Regression model is higher than the performance observed with Kmean when the dataset is clean (about 96%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0]\n",
      " [ 2 18]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = metrics.confusion_matrix(y1_test, y1_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test  predictions\n",
       "4   True        False\n",
       "12  True        False"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zoom-in the 2 False Negative\n",
    "# Extract the test and predictions values\n",
    "test = pd.Series(y1_test.reset_index().iloc[:,1],name='test')\n",
    "pred = pd.Series(y1_pred,name='predictions')\n",
    "\n",
    "# Create a dataframe with the informations\n",
    "tmp = pd.concat([test, pred], axis=1)\n",
    "\n",
    "# Select the rows when the 2 columns are not matched\n",
    "tmp[tmp['test'] != tmp['predictions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On the dataset with outliers, we can see that 2 genuine banknotes have been mislabelled as fake (False Negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  1]\n",
      " [ 0 19]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = metrics.confusion_matrix(y2_test, y2_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On the dataset without outliers, 1 fake banknotes have been placed into the genuine set (False positive).\n",
    "\n",
    "The question here is: Which model to choose? \n",
    "- The first model trained on the dataset with outliers, is somehow too selective. It mislabelled 2 genuine banknotes as fake. The global accuracy is still good with 94%.\n",
    "- The second model trained on the dataset without outliers, has a better accuracy (97%) but it mislabelled a fake banknote as genuine.\n",
    "\n",
    "In spite of having a lower accuracy, we choose to keep the first model because mislabelling a fake banknote is more \"costly\" than mislabelling a genuine banknote for a counterfake algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we wrap all the steps together:\n",
    "- Reading the data\n",
    "- Standardization\n",
    "- PCA\n",
    "- Predictions by the trained model\n",
    "- Extracting the results and probabilities associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_detector(dataset,idxcol):\n",
    "    \n",
    "    #Read the data\n",
    "    df = pd.read_csv(Path.cwd()/dataset)\n",
    "    df = df.set_index(idxcol) # set id as index\n",
    "    df.drop('diagonal', inplace=True, axis=1) # Drop the variable diagonal \n",
    "\n",
    "    #Standardization\n",
    "    mask = df.columns\n",
    "    df[mask] = StandardScaler().fit_transform(df[mask])\n",
    "    \n",
    "    # Extract features\n",
    "    features = df.columns\n",
    "    \n",
    "    # Reduce dimension with PCA\n",
    "    pca = PCA()\n",
    "    name = ['PC1','PC2','PC3','PC4','PC5']\n",
    "    df_PCA = df.reset_index()[['id']]\n",
    "    df_PCA[name] = pd.DataFrame(pca.fit_transform(df.values),columns=[name])\n",
    "    \n",
    "    # Predict\n",
    "    results = df_PCA.iloc[:,0:4].copy()\n",
    "    results['proba_Fake'] = lgr2.predict_proba(df_PCA.iloc[:,1:4])[:,0]\n",
    "    results['proba_Genuine'] = lgr2.predict_proba(df_PCA.iloc[:,1:4])[:,1]\n",
    "    results['predict_is_genuine'] = lgr2.predict(df_PCA.iloc[:,1:4])\n",
    "    \n",
    "    return results[['id','proba_Fake','proba_Genuine','predict_is_genuine']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>proba_Fake</th>\n",
       "      <th>proba_Genuine</th>\n",
       "      <th>predict_is_genuine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A_1</td>\n",
       "      <td>0.022523</td>\n",
       "      <td>0.977477</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A_2</td>\n",
       "      <td>0.042593</td>\n",
       "      <td>0.957407</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_3</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.998473</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_4</td>\n",
       "      <td>0.983772</td>\n",
       "      <td>0.016228</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_5</td>\n",
       "      <td>0.994046</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  proba_Fake  proba_Genuine  predict_is_genuine\n",
       "0  A_1    0.022523       0.977477                True\n",
       "1  A_2    0.042593       0.957407                True\n",
       "2  A_3    0.001527       0.998473                True\n",
       "3  A_4    0.983772       0.016228               False\n",
       "4  A_5    0.994046       0.005954               False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We test the function on a new set\n",
    "fake_detector('example.csv','id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
